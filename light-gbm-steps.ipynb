{"cells":[{"metadata":{},"cell_type":"markdown","source":"# XG Boost Steps\n#### 1)Import and split\n#### 2)Set and fit the model\n#### 3)Predict\n#### 4)Model Tuning\n#### 5)Find best params, set and fit the model again, find final RMSE."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import scale \nfrom sklearn import model_selection\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import BaggingRegressor\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hit = pd.read_csv(\"../input/hittlers/Hitters.csv\")\ndf = hit.copy()\ndf = df.dropna()\ndms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\ny = df[\"Salary\"]\nX_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\nX = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=42)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Set and fit the model","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install lightgbm","execution_count":4,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: lightgbm in /opt/conda/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from lightgbm) (0.22.2.post1)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.4.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lightgbm) (1.18.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->lightgbm) (0.14.1)\n\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_model=LGBMRegressor()\nlgbm_model.fit(X_train,y_train)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n              importance_type='split', learning_rate=0.1, max_depth=-1,\n              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=lgbm_model.predict(X_test,num_iteration=lgbm_model.best_iteration_)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_test,y_pred))","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"363.8712087611089"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Tuning","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_model","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n              importance_type='split', learning_rate=0.1, max_depth=-1,\n              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n              random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Important Params\n#learning_rate\n#n_estimators\n#max_depth","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_grid = {\n    'colsample_bytree': [0.4, 0.5,0.6,0.9,1],\n    'learning_rate': [0.01, 0.1, 0.5,1],\n    'n_estimators': [20, 40, 100, 200, 500,1000],\n    'max_depth': [1,2,3,4,5,6,7,8] }\n\nlgbm = LGBMRegressor()\nlgbm_cv_model = GridSearchCV(lgbm, lgbm_grid, cv=10, n_jobs = -1, verbose = 2)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_cv_model.fit(X_train,y_train)","execution_count":14,"outputs":[{"output_type":"stream","text":"Fitting 10 folds for each of 960 candidates, totalling 9600 fits\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.0s\n[Parallel(n_jobs=-1)]: Done 516 tasks      | elapsed:   12.1s\n[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed:   29.3s\n[Parallel(n_jobs=-1)]: Done 2460 tasks      | elapsed:   54.9s\n[Parallel(n_jobs=-1)]: Done 3920 tasks      | elapsed:  1.5min\n[Parallel(n_jobs=-1)]: Done 5700 tasks      | elapsed:  2.2min\n[Parallel(n_jobs=-1)]: Done 7808 tasks      | elapsed:  3.1min\n[Parallel(n_jobs=-1)]: Done 9593 out of 9600 | elapsed:  3.9min remaining:    0.2s\n[Parallel(n_jobs=-1)]: Done 9600 out of 9600 | elapsed:  3.9min finished\n","name":"stderr"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"GridSearchCV(cv=10, error_score=nan,\n             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n                                     colsample_bytree=1.0,\n                                     importance_type='split', learning_rate=0.1,\n                                     max_depth=-1, min_child_samples=20,\n                                     min_child_weight=0.001, min_split_gain=0.0,\n                                     n_estimators=100, n_jobs=-1, num_leaves=31,\n                                     objective=None, random_state=None,\n                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n                                     subsample=1.0, subsample_for_bin=200000,\n                                     subsample_freq=0),\n             iid='deprecated', n_jobs=-1,\n             param_grid={'colsample_bytree': [0.4, 0.5, 0.6, 0.9, 1],\n                         'learning_rate': [0.01, 0.1, 0.5, 1],\n                         'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],\n                         'n_estimators': [20, 40, 100, 200, 500, 1000]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring=None, verbose=2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_cv_model.best_params_","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"{'colsample_bytree': 0.4,\n 'learning_rate': 0.1,\n 'max_depth': 5,\n 'n_estimators': 40}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_tuned = LGBMRegressor(learning_rate = 0.1, \n                           max_depth = 5, \n                           n_estimators = 40,\n                          colsample_bytree = 0.4)\n\nlgbm_tuned = lgbm_tuned.fit(X_train,y_train)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred= lgbm_tuned.predict(X_test)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_test, y_pred))","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"377.8415676535648"},"metadata":{}}]},{"metadata":{"trusted":false},"cell_type":"code","source":"# We found 413 for KNN, \n#          367 for SVR,\n#          363 for Artifical Neural Network.\n#          376 for CART\n#          349 for Bagged Trees\n#          350 for Random Forest\n#          344 for GBM\n#          355 for XG Boosting\n#And now,  377 for Light GBM\n\n#In these models, the best one is GBM model for \"hitters\" data set, till now.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}